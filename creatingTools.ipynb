{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arxiv\n",
    "# pip install arxiv\n",
    "# pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia -Tool 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used inbuilt tools in wikipedia\n",
    "api_wrapper_wiki = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=250)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper_wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arxiv Tool 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper_arxiv = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=250)\n",
    "arxiv = ArxivQueryRun(api_wrapper=api_wrapper_arxiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki, arxiv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### any web page Tool 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E85CA76110>, search_kwargs={})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader('https://groq.com/pricing/')\n",
    "docs = loader.load()\n",
    "documents = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)\n",
    "vectordb = FAISS.from_documents(documents, OllamaEmbeddings(model='gemma2:2b'))\n",
    "retriever = vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "# retriver, name, question\n",
    "retriever_tool = create_retriever_tool(retriever, 'langsmith_search', 'search any information about langsmith')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'd:\\\\generativeAi\\\\langchain\\\\myenv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)),\n",
       " Tool(name='langsmith_search', description='search any information about langsmith', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001E8699734C0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E85CA76110>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001E869D0E020>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E85CA76110>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n'))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [wiki, arxiv, retriever_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the tools with agents and llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name = 'Llama3-8b-8192')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# This is a alraedy exsit prompt\n",
    "prompt = hub.pull('hwchase17/openai-functions-agent')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By themselves, language models can't take actions - they just output text. Agents are systems that take a high-level task and use an LLM as a reasoning engine to decide what actions to take and execute those actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001E868FA3CE0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001E868FA3CE0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001E85D745610>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001E85D579410>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith_search', 'description': 'search any information about langsmith', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001E868FA3CE0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001E868FA3CE0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001E85D745610>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001E85D579410>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith_search', 'description': 'search any information about langsmith', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'd:\\\\generativeAi\\\\langchain\\\\myenv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)), Tool(name='langsmith_search', description='search any information about langsmith', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001E8699734C0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E85CA76110>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001E869D0E020>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E85CA76110>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n'))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "agent_executer = AgentExecutor(agent= agent, tools = tools, verbose=True)\n",
    "agent_executer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Machine learning'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks wit\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'Machine learning'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2019-09-08\n",
      "Title: Lecture Notes: Optimization for Machine Learning\n",
      "Authors: Elad Hazan\n",
      "Summary: Lecture notes on optimization for machine learning, derived from a course at\n",
      "Princeton University and tutorials given in MLSS, Buenos Aires, as\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'Machine learning optimization'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mWikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. Wikipedia is the largest and most-read reference work in history.\n",
      "\n",
      "Wikipedia | 🦜️🔗 LangChain\n",
      "\n",
      "First, you need to install wikipedia python package.\n",
      "%pip install --upgrade --quiet  wikipedia\n",
      "from langchain_community.tools import WikipediaQueryRunfrom langchain_community.utilities import WikipediaAPIWrapperAPI Reference:WikipediaQueryRun | WikipediaAPIWrapper\n",
      "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
      "wikipedia.run(\"HUNTER X HUNTER\")\n",
      "'Page: Hunter × Hunter\\nSummary: Hunter × Hunter (stylized as HUNTER×HUNTER and pronounced \"hunter hunter\") is a Japanese manga series written and illustrated by Yoshihiro Togashi. It has been serialized in Shueisha\\'s shōnen manga magazine Weekly Shōnen Jump since March 1998, although the manga has frequently gone on extended hiatuses since 2006. Its chapters have been collected in 37 tankōbon volumes as of November 2022. The story focuses on a young boy named Gon Freecss who discovers that his father, who left him at a young age, is actually a world-renowned Hunter, a licensed professional who specializes in fantastical pursuits such as locating rare or unidentified animal species, treasure hunting, surveying unexplored enclaves, or hunting down lawless individuals. Gon departs on a journey to become a Hunter and eventually find his father. Along the way, Gon meets various other Hunters and encounters the paranormal.\\nHunter × Hunter was adapted into a 62-episode anime television series produced by Nippon Animation and directed by Kazuhiro Furuhashi, which ran on Fuji Television from October 1999 to March 2001. Three separate original video animations (OVAs) totaling 30 episodes were subsequently produced by Nippon Animation and released in Japan from 2002 to 2004. A second anime television series by Madhouse aired on Nippon Television from October 2011 to September 2014, totaling 148 episodes, with two animated theatrical films released in 2013. There are also numerous audio albums, video games, musicals, and other media based on Hunter × Hunter.\\nThe manga has been translated into English and released in North America by Viz Media since April 2005. Both television series have been also licensed by Viz Media, with the first series having aired on the Funimation Channel in 2009 and the second series broadcast on Adult Swim\\'s Toonami programming block from April 2016 to June 2019.\\nHunter × Hunter has been a huge critical and financial success and has become one of the best-selling manga series of all time, having over 84 million copies in circulation by July 2022.\\n\\nPage: Hunter × Hunter (2011 TV series)\\nSummary: Hunter × Hunter is an anime television series that aired from 2011 to 2014 based on Yoshihiro Togashi\\'s manga series Hunter × Hunter. The story begins with a young boy named Gon Freecss, who one day discovers that the father who he thought was dead, is in fact alive and well. He learns that his father, Ging, is a legendary \"Hunter\", an individual who has proven themselves an elite member of humanity. Despite the fact that Ging left his son with his relatives in order to pursue his own dreams, Gon becomes determined to follow in his father\\'s footsteps, pass the rigorous \"Hunter Examination\", and eventually find his father to become a Hunter in his own right.\\nThis new Hunter × Hunter anime was announced on July 24, 2011. It is a complete reboot starting from the beginning of the original manga, with no connection to the first anime television series from 1999. Produced by Nippon TV, VAP, Shueisha and Madhouse, the series is directed by Hiroshi Kōjina, with Atsushi Maekawa and Tsutomu Kamishiro handling series composition, Takahiro Yoshimatsu designing the characters and Yoshihisa Hirano composing the music. Instead of having the old cast reprise their roles for the new adaptation, the series features an entirely new cast to voice the characters. The new series premiered airing weekly on Nippon TV and the nationwide Nippon News Network from October 2, 2011.  The series started to be collected in both DVD and Blu-ray format on January 25, 2012. Viz Media has licensed the anime for a DVD/Blu-ray release in North America with an English dub. On television, the series began airing on Adult Swim\\'s Toonami programming block on April 17, 2016, and ended on June 23, 2019.The anime series\\' opening theme is alternated between the song \"Departure!\" and an alternate version titled \"Departure! -Second Version-\" both sung by Galneryus\\' voc'\n",
      "Related​\n",
      "\n",
      "Tool conceptual guide\n",
      "Tool how-to guides\n",
      "Edit this pageWas this page helpful?PreviousWikidataNextWolfram AlphaRelatedCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright © 2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mIt seems like the tool call \"call_91fw\" provided a lot of information related to Wikipedia and LangChain. Since the question was about machine learning, I'll try to summarize the relevant information and provide a direct response.\n",
      "\n",
      "Machine learning is a subset of artificial intelligence that involves the use of algorithms and statistical models to enable machines to learn from data and make predictions or decisions without being explicitly programmed.\n",
      "\n",
      "The tool call provided some information about optimization for machine learning, which is a crucial aspect of machine learning. Optimization is the process of finding the best possible solution from a large number of possibilities, and it's often used in machine learning to improve the performance of models.\n",
      "\n",
      "However, since the question was not specific to optimization for machine learning, I'll provide a more general response. Machine learning is a rapidly growing field with a wide range of applications, including image and speech recognition, natural language processing, and predictive analytics. It's used in many industries, including healthcare, finance, and education, to name a few.\n",
      "\n",
      "I hope this response provides a good overview of machine learning, and I'll be happy to provide more information if you have any specific questions or topics you'd like to discuss.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is machine learning',\n",
       " 'output': 'It seems like the tool call \"call_91fw\" provided a lot of information related to Wikipedia and LangChain. Since the question was about machine learning, I\\'ll try to summarize the relevant information and provide a direct response.\\n\\nMachine learning is a subset of artificial intelligence that involves the use of algorithms and statistical models to enable machines to learn from data and make predictions or decisions without being explicitly programmed.\\n\\nThe tool call provided some information about optimization for machine learning, which is a crucial aspect of machine learning. Optimization is the process of finding the best possible solution from a large number of possibilities, and it\\'s often used in machine learning to improve the performance of models.\\n\\nHowever, since the question was not specific to optimization for machine learning, I\\'ll provide a more general response. Machine learning is a rapidly growing field with a wide range of applications, including image and speech recognition, natural language processing, and predictive analytics. It\\'s used in many industries, including healthcare, finance, and education, to name a few.\\n\\nI hope this response provides a good overview of machine learning, and I\\'ll be happy to provide more information if you have any specific questions or topics you\\'d like to discuss.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({'input': \"what is machine learning\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Langsmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mNo good Wikipedia Search Result was found\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'No good Wikipedia Search Result was found'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mWikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. Wikipedia is the largest and most-read reference work in history.\n",
      "\n",
      "Wikipedia | 🦜️🔗 LangChain\n",
      "\n",
      "Tool conceptual guide\n",
      "Tool how-to guides\n",
      "Edit this pageWas this page helpful?PreviousWikidataNextWolfram AlphaRelatedCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright © 2024 LangChain, Inc.\n",
      "\n",
      "First, you need to install wikipedia python package.\n",
      "%pip install --upgrade --quiet  wikipedia\n",
      "from langchain_community.tools import WikipediaQueryRunfrom langchain_community.utilities import WikipediaAPIWrapperAPI Reference:WikipediaQueryRun | WikipediaAPIWrapper\n",
      "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
      "wikipedia.run(\"HUNTER X HUNTER\")\n",
      "'Page: Hunter × Hunter\\nSummary: Hunter × Hunter (stylized as HUNTER×HUNTER and pronounced \"hunter hunter\") is a Japanese manga series written and illustrated by Yoshihiro Togashi. It has been serialized in Shueisha\\'s shōnen manga magazine Weekly Shōnen Jump since March 1998, although the manga has frequently gone on extended hiatuses since 2006. Its chapters have been collected in 37 tankōbon volumes as of November 2022. The story focuses on a young boy named Gon Freecss who discovers that his father, who left him at a young age, is actually a world-renowned Hunter, a licensed professional who specializes in fantastical pursuits such as locating rare or unidentified animal species, treasure hunting, surveying unexplored enclaves, or hunting down lawless individuals. Gon departs on a journey to become a Hunter and eventually find his father. Along the way, Gon meets various other Hunters and encounters the paranormal.\\nHunter × Hunter was adapted into a 62-episode anime television series produced by Nippon Animation and directed by Kazuhiro Furuhashi, which ran on Fuji Television from October 1999 to March 2001. Three separate original video animations (OVAs) totaling 30 episodes were subsequently produced by Nippon Animation and released in Japan from 2002 to 2004. A second anime television series by Madhouse aired on Nippon Television from October 2011 to September 2014, totaling 148 episodes, with two animated theatrical films released in 2013. There are also numerous audio albums, video games, musicals, and other media based on Hunter × Hunter.\\nThe manga has been translated into English and released in North America by Viz Media since April 2005. Both television series have been also licensed by Viz Media, with the first series having aired on the Funimation Channel in 2009 and the second series broadcast on Adult Swim\\'s Toonami programming block from April 2016 to June 2019.\\nHunter × Hunter has been a huge critical and financial success and has become one of the best-selling manga series of all time, having over 84 million copies in circulation by July 2022.\\n\\nPage: Hunter × Hunter (2011 TV series)\\nSummary: Hunter × Hunter is an anime television series that aired from 2011 to 2014 based on Yoshihiro Togashi\\'s manga series Hunter × Hunter. The story begins with a young boy named Gon Freecss, who one day discovers that the father who he thought was dead, is in fact alive and well. He learns that his father, Ging, is a legendary \"Hunter\", an individual who has proven themselves an elite member of humanity. Despite the fact that Ging left his son with his relatives in order to pursue his own dreams, Gon becomes determined to follow in his father\\'s footsteps, pass the rigorous \"Hunter Examination\", and eventually find his father to become a Hunter in his own right.\\nThis new Hunter × Hunter anime was announced on July 24, 2011. It is a complete reboot starting from the beginning of the original manga, with no connection to the first anime television series from 1999. Produced by Nippon TV, VAP, Shueisha and Madhouse, the series is directed by Hiroshi Kōjina, with Atsushi Maekawa and Tsutomu Kamishiro handling series composition, Takahiro Yoshimatsu designing the characters and Yoshihisa Hirano composing the music. Instead of having the old cast reprise their roles for the new adaptation, the series features an entirely new cast to voice the characters. The new series premiered airing weekly on Nippon TV and the nationwide Nippon News Network from October 2, 2011.  The series started to be collected in both DVD and Blu-ray format on January 25, 2012. Viz Media has licensed the anime for a DVD/Blu-ray release in North America with an English dub. On television, the series began airing on Adult Swim\\'s Toonami programming block on April 17, 2016, and ended on June 23, 2019.The anime series\\' opening theme is alternated between the song \"Departure!\" and an alternate version titled \"Departure! -Second Version-\" both sung by Galneryus\\' voc'\n",
      "Related​\u001b[0m\u001b[32;1m\u001b[1;3mIt seems like you've provided a lot of information about Wikipedia and LangChain! 😊\n",
      "\n",
      "As a helpful assistant, I'll try to summarize the main points for you:\n",
      "\n",
      "1. Wikipedia is a multilingual online encyclopedia written by a community of volunteers.\n",
      "2. LangChain is a tool that provides information on various topics, including Wikipedia.\n",
      "3. To use LangChain, you need to install the Wikipedia Python package and run a query.\n",
      "\n",
      "Regarding your original question, it seems like you were asking about Langsmith, which is a tool that provides information on various topics. However, based on the output you provided, it appears that Langsmith is actually a community-driven platform that provides information on a wide range of topics, including Hunter × Hunter.\n",
      "\n",
      "If you have any further questions or would like to know more about Langsmith or Wikipedia, feel free to ask! 😊\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is langsmith',\n",
       " 'output': \"It seems like you've provided a lot of information about Wikipedia and LangChain! 😊\\n\\nAs a helpful assistant, I'll try to summarize the main points for you:\\n\\n1. Wikipedia is a multilingual online encyclopedia written by a community of volunteers.\\n2. LangChain is a tool that provides information on various topics, including Wikipedia.\\n3. To use LangChain, you need to install the Wikipedia Python package and run a query.\\n\\nRegarding your original question, it seems like you were asking about Langsmith, which is a tool that provides information on various topics. However, based on the output you provided, it appears that Langsmith is actually a community-driven platform that provides information on a wide range of topics, including Hunter × Hunter.\\n\\nIf you have any further questions or would like to know more about Langsmith or Wikipedia, feel free to ask! 😊\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({'input': \"what is langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Groq pricing'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: List of unicorn startup companies\n",
      "Summary: This is a list of unicorn startup companies:\n",
      "In finance, a unicorn is a privately held startup company with a current valuation of US$1 billion or more. Notable lists of unicorn companies are maintaine\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Groq pricing'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: List of unicorn startup companies\n",
      "Summary: This is a list of unicorn startup companies:\n",
      "In finance, a unicorn is a privately held startup company with a current valuation of US$1 billion or more. Notable lists of unicorn companies are maintaine\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'Groq pricing'}`\n",
      "responded: It seems like the previous tool call did not yield the expected result. Since the result was the same as before, I will try again using a different tool.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2024-10-13\n",
      "Title: Empowering Dysarthric Speech: Leveraging Advanced LLMs for Accurate Speech Correction and Multimodal Emotion Analysis\n",
      "Authors: Kaushal Attaluri, Anirudh CHVS, Sireesha Chittepu\n",
      "Summary: Dysarthria is a motor speech disord\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'Groq pricing'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mNecessary\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "Necessary\n",
      "\n",
      "Always Enabled\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\tNecessary cookies are absolutely essential for the website to function properly. This category only includes cookies that ensures basic functionalities and security features of the website. These cookies do not store any personal information.\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tNon-necessary\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "Non-necessary\n",
      "\n",
      "\t\t\t\t\t\t\t\t\tAny cookies that may not be particularly necessary for the website to function and is used specifically to collect user personal data via analytics, ads, other embedded contents are termed as non-necessary cookies. It is mandatory to procure user consent prior to running these cookies on your website.\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "SAVE & ACCEPT\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      " Search\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " Products \n",
      "\n",
      "Pricing\n",
      "\n",
      "\n",
      "Products Overview\n",
      "\n",
      "\n",
      "Enterprise Access\n",
      "\n",
      "\n",
      "GroqCloud™ Platform\n",
      "\n",
      "\n",
      "GroqRack™ Cluster\n",
      "\n",
      " Developers \n",
      "\n",
      "Free API Key  \n",
      "\n",
      "\n",
      "Dev Console  \n",
      "\n",
      "\n",
      "Discord   \n",
      "\n",
      "\n",
      "Groq Libraries   \n",
      "\n",
      "\n",
      "Community\n",
      "\n",
      "\n",
      "Showcase\n",
      "\n",
      " Insights \n",
      "\n",
      "Inference\n",
      "\n",
      "\n",
      "Blog\n",
      "\n",
      "\n",
      "Events\n",
      "\n",
      "\n",
      "GroqDocs\n",
      "\n",
      "\n",
      "Videos\n",
      "\n",
      "GroqRack™ Cluster\n",
      "\n",
      " Developers \n",
      "\n",
      "Free API Key  \n",
      "\n",
      "\n",
      "Dev Console  \n",
      "\n",
      "\n",
      "Discord   \n",
      "\n",
      "\n",
      "Groq Libraries   \n",
      "\n",
      "\n",
      "Community\n",
      "\n",
      "\n",
      "Showcase\n",
      "\n",
      " Insights \n",
      "\n",
      "Inference\n",
      "\n",
      "\n",
      "Blog\n",
      "\n",
      "\n",
      "Events\n",
      "\n",
      "\n",
      "GroqDocs\n",
      "\n",
      "\n",
      "Videos\n",
      "\n",
      "\n",
      "Press Releases\n",
      "\n",
      "\n",
      "Brand Guidelines\n",
      "\n",
      " About \n",
      "\n",
      "About Groq\n",
      "\n",
      "\n",
      "In the News\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "Careers\n",
      "\n",
      "\n",
      "Never miss a Groq update! Sign up below for our latest news. \n",
      "\n",
      "\n",
      "Sign up for Groq updates\n",
      "\n",
      "\n",
      "Contact Us\n",
      "Privacy\n",
      "Terms of Use\n",
      "Security\n",
      "Trademark Policy\n",
      "Cookie Policy\n",
      "Brand Guidelines\n",
      " \n",
      "\n",
      "Contact Us\n",
      "Privacy\n",
      "Terms of Use\n",
      "Security\n",
      "Trademark Policy\n",
      "Cookie Policy\n",
      "Brand Guidelines\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "Youtube\n",
      " \n",
      "\n",
      "Threads\n",
      " \n",
      "\n",
      "Linkedin\n",
      " \n",
      "\n",
      "Instagram\n",
      " \n",
      "\n",
      "\n",
      "The latest Groq news. Delivered to your inbox.\n",
      "\n",
      "Llama 3 Groq 8B Tool Use Preview 8k1250$0.19\n",
      "(5.26M / $1)*$0.19\n",
      "(5.26M / $1)*\n",
      "\n",
      "\n",
      "Llama Guard 3 8B 8k765$0.20\n",
      "(5M / $1)*$0.20\n",
      "(5M / $1)*\n",
      "\n",
      "\n",
      "Llama 3.3 70B SpecDec 8k1600$0.59\n",
      "(1.69M / $1)*$0.99\n",
      "(1.01M / $1)*\n",
      "\n",
      "\n",
      "*Approximate number of tokens per $ \n",
      "\n",
      "Automatic Speech Recognition (ASR) Models \n",
      "\n",
      "AI ModelSpeed FactorPrice(Per Hour Transcribed)\n",
      "\n",
      "\n",
      "Whisper V3 Large189x$0.111*\n",
      "\n",
      "\n",
      "Whisper Large v3 Turbo216x$0.04*\n",
      "\n",
      "\n",
      "Distil-Whisper250x$0.02*\n",
      "\n",
      "\n",
      "*For ASR models above, Groq charges a minimum of 10 seconds per request. \n",
      "\n",
      "Vision Models \n",
      "\n",
      "AI ModelInput Token Price(per M tokens)Output Token Price(per M tokens)\n",
      "\n",
      "\n",
      "Llama 3.2 11B Vision 8k (Preview)$0.18*$0.18*\n",
      "\n",
      "\n",
      "Llama 3.2 90B Vision 8k (Preview)$0.90*$0.90*\n",
      "\n",
      "\n",
      "*For vision models, images are billed at 6,400 tokens per image. \n",
      "\n",
      "For enterprise API solutions or on-prem deployments, please fill out the form on our Enterprise Access Page. \n",
      "\n",
      "\n",
      "Never miss a Groq update! Sign up below for our latest news. \n",
      "\n",
      "\n",
      "Sign up for Groq updates\n",
      "\n",
      "Never miss a Groq update! Sign up below for our latest news. \n",
      "\n",
      "\n",
      "Sign up for Groq updates\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "© 2024 Groq, Inc., All rights reserved. \n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "Youtube\n",
      " \n",
      "\n",
      "Threads\n",
      " \n",
      "\n",
      "Linkedin\n",
      " \n",
      "\n",
      "Instagram\n",
      " \n",
      "\n",
      "\n",
      "This site uses cookies to operate our website and analyze website traffic. Read MoreAcceptReject Privacy & Cookies Policy\n",
      "\n",
      "\n",
      "Close\n",
      "\n",
      "\n",
      "Privacy Overview \n",
      "This website uses cookies to improve your experience while you navigate through the website. Out of these, the cookies that are categorized as necessary are stored on your browser as they are essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may affect your browsing experience.\n",
      "\n",
      " \n",
      "\n",
      "\t\t\t\t\t\t\t\tNecessary\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "Necessary\n",
      "\n",
      "Always Enabled\u001b[0m\u001b[32;1m\u001b[1;3mIt looks like the tool call yielded some information about Groq pricing! Since the tool call was successful, I can now provide a direct response to the user's original question.\n",
      "\n",
      "Groq pricing information includes various plans and models for Automatic Speech Recognition (ASR) and Vision models, with different input and output token prices per million tokens. The pricing also includes a minimum of 10 seconds per request for ASR models.\n",
      "\n",
      "Please note that the user may want to explore the provided pricing information further to get a better understanding of the costs involved.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is groq pricing',\n",
       " 'output': \"It looks like the tool call yielded some information about Groq pricing! Since the tool call was successful, I can now provide a direct response to the user's original question.\\n\\nGroq pricing information includes various plans and models for Automatic Speech Recognition (ASR) and Vision models, with different input and output token prices per million tokens. The pricing also includes a minimum of 10 seconds per request for ASR models.\\n\\nPlease note that the user may want to explore the provided pricing information further to get a better understanding of the costs involved.\"}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({'input': \"what is groq pricing\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
